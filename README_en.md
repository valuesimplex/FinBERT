<h1 align="center">âš¡ï¸FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in Finance-Specific Deployment of LLMs</h1>
<p align="center">
    <a href="https://huggingface.co/valuesimplex-ai-lab/">
        <img alt="Build" src="https://img.shields.io/badge/FinBERT2--Suits-ğŸ¤—-yellow">
    </a>
    <a href="https://github.com/valuesimplex/FinBERT2">
        <img alt="Build" src="https://img.shields.io/badge/Contribution-Welcome-blue">
    </a>
    <a href="https://github.com/valuesimplex/FinBERT2/LICENSE">
        <img alt="License" src="https://img.shields.io/badge/LICENSE-MIT-green">
    </a>

<h4 align="center">
    <p>
        <a href="#Background">Background</a> |
        <a href="#Installation">Installation</a> |
        <a href="#Model-List">Model List</a> |
        <a href="#Reference">Reference</a> |
        <a href="#Citation">Citation</a> |
        <a href="#License">License</a> 
    <p>
</h4>

[ä¸­æ–‡](README.md)  |  [English](README_en.md) 


![projects](./pics/projects.svg)

ğŸŒŸPaperğŸŒŸ: https://dl.acm.org/doi/10.1145/3711896.3737219

ğŸŒŸDatasets and CheckpointsğŸŒŸ: https://huggingface.co/valuesimplex-ai-lab/


## Background

The open-source FinBERT2 is the second-generation upgrade of the FinBERT model (open-sourced in 2020) by EntropyReduce Technology. FinBERT2 is deeply pre-trained on high-quality Chinese financial corpus of over 32 billion tokens, aiming to improve the performance of Large Language Models (LLMs) in financial domain application deployment.

This open-source work includes the pre-trained model FinBERT2, fine-tuned models for specific downstream tasks, and related datasets to support more innovative research and application practices in the fintech field, and to jointly promote the prosperity of the financial AI ecosystem with community partners.

## FinBERT2 Introduction

![projects](./pics/overview.png)

FinBERT2 can bridge the gap in LLM deployment in finance-specific scenarios through the following aspects:

1. **Large-scale Chinese Financial Corpus Pre-training**: The financial corpus pre-training scale of FinBERT2 exceeds 32 billion tokens, and we will open-source this model subsequently. To our knowledge, among open-source Chinese financial domain BERT-like models, this will be the model with the largest pre-training corpus scale and best performance;

2. **Superior Financial Text Classification Performance**: FinBERT2 outperforms other (Fin)BERT variants by 0.4%-3.3% on average across various financial classification tasks, and leads mainstream large language models (such as GPT-4-turbo, Claude 3.5 Sonnet, Qwen2) by 9.7%-12.3%;

3. **Excellent Vectorized Information Retrieval (Fin-Retrievers)**: As a retrieval component of RAG systems, FinBERT2 surpasses open-source and commercial vectorization models in performance. On five typical financial retrieval tasks, FinBERT2 achieves an average performance improvement of +6.8% compared to BGE-base-zh and +4.2% compared to OpenAI's text-embedding-3-large.

For more detailed introductions and evaluation results, please refer to our original paper.
 
# Installation
### 1. Clone the project source code
```
git clone https://github.com/valuesimplex/FinBERT2.git
```
### 2. Create a virtual environment
```bash
conda create --name FinBERT2 python=3.11
conda activate FinBERT2
```

### 3. Install dependencies

Run the following command to install all dependencies listed in `requirements.txt`:
```bash
pip install -r requirements.txt
```

### 4. Run the project
Once installation is complete, you can enter the corresponding folder to run the project:
####  File Structure

```
FinBERT2
â”œâ”€â”€ Fin-labeler                                    # * Fine-tuning models for classification tasks
â”‚   â”œâ”€â”€ SC_2/                                      # * Sentiment classification dataset (2-class)
â”‚   â”œâ”€â”€ runclassify.sh                             # * Shell script for running classification
â”‚   â””â”€â”€ sequence_inference.py                      # * Sequence inference script
â”œâ”€â”€ Fin-retriever                                  # * Contrastive learning-based retrieval models
â”‚   â”œâ”€â”€ contrastive_finetune.sh                    # * Shell script for contrastive fine-tuning
â”‚   â””â”€â”€ finetune_traindata_sample.json             # * Sample training data for retrieval fine-tuning
â”œâ”€â”€ Fin-Topicmodel                                 # * Topic modeling for financial titles
â”‚   â”œâ”€â”€ Fin-Topicmodel.ipynb                       # * Main notebook for topic modeling
â”œâ”€â”€ FinBERT2/                                      # * Core FinBERT2 model implementation
â”‚   â”œâ”€â”€ pretrain/                                  # * Pre-training scripts and modules
â”‚   â”‚   â”œâ”€â”€ run_mlm.sh                             # * MLM training script
â”‚   â”‚   â””â”€â”€ run_retromae.sh                        # * RetroMAE training script
â”‚   â””â”€â”€ pretrain_wordpiece_tokenizer/              # * WordPiece tokenizer training
â”‚       â”œâ”€â”€ spm.sh                                 # * SentencePiece training script
```


## Quick Start
### Incremental pre-training on FinBERT2 pre-trained model
```
cd FinBERT2\pretrain
sh run_mlm.sh
```
### Using FinBERT2 for financial text classification

```
# Fine-tuning
cd FinBERT2\Fin-labeler
sh runclassify.sh

# Inference
python sequence_inference.py
```

### Contrastive learning fine-tuning

Refer to the [FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune/embedder) project

### Using Fin-Retriever-base vector retrieval model

```
from sentence_transformers import SentenceTransformer
import numpy as np

# Load the Fin-Retrievers model.
model = SentenceTransformer('valuesimplex-ai-lab/fin-retriever-base')

# Set the original query
query = "ç¾è”å‚¨åŠ æ¯å¯¹ç§‘æŠ€è‚¡çš„å½±å“"

# Key step: Add a prompt to the query to ensure consistency with the model's training
optimized_query = "ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š" + query

# Build a document list (including structured information such as title, organization, author, etc.)
documents = [
    {
        "title": "ç¾è”å‚¨åŠ æ¯å¯¹ç§‘æŠ€è‚¡ä¼°å€¼å½±å“åˆ†æ",
        "company": "",  
        "institution": "æ‘©æ ¹å£«ä¸¹åˆ©",
        "industry": "ç§‘æŠ€ç»¼åˆ",
        "author": "å¼ ä¼Ÿ",
        "type": "ç­–ç•¥æŠ¥å‘Š",
        "content": "2023å¹´ç¾è”å‚¨è¿ç»­åŠ æ¯å¯¼è‡´ç§‘æŠ€è‚¡ä¼°å€¼å¤§å¹…å›è°ƒï¼Œç‰¹åˆ«æ˜¯é«˜æˆé•¿æ€§ç§‘æŠ€å…¬å¸ã€‚å†å²æ•°æ®æ˜¾ç¤ºï¼Œåˆ©ç‡æ¯ä¸Šå‡25ä¸ªåŸºç‚¹ï¼Œç§‘æŠ€æ¿å—å¹³å‡ä¸‹è·Œ3.5%ã€‚FAANGè‚¡ç¥¨å—å†²å‡»æœ€æ˜æ˜¾ï¼Œå…¶ä¸­Metaå’ŒNetflixä¼°å€¼å‹ç¼©å¹…åº¦æœ€å¤§ã€‚"
    },
    {
        "title": "ç¾è”å‚¨åŠ æ¯å¯¹å…¨çƒèµ„äº§é…ç½®çš„å½±å“",
        "company": "",  
        "institution": "ç‘é“¶",
        "industry": "å®è§‚ç»æµ",
        "author": "æå¼º",
        "type": "å®è§‚ç ”ç©¶",
        "content": "æœ¬æ–‡ç³»ç»Ÿåˆ†æç¾è”å‚¨åŠ æ¯å¯¹å…¨çƒè‚¡å€ºæ±‡å¸‚çš„å½±å“ï¼Œç§‘æŠ€è‚¡ä½œä¸ºæƒç›Šèµ„äº§çš„ä¸€éƒ¨åˆ†ï¼Œå…¶æ³¢åŠ¨åœ¨æœ¬æ–‡ä¸­è¢«çº³å…¥æ•´ä½“å¸‚åœºåˆ†ææ¡†æ¶ã€‚æŠ¥å‘Šç‰¹åˆ«å…³æ³¨äº†æ–°å…´å¸‚åœºè´§å¸æ³¢åŠ¨å’Œå•†å“ä»·æ ¼å˜åŒ–ï¼Œç§‘æŠ€è‚¡ä»…å åˆ†æç¯‡å¹…çš„15%ã€‚"
    },
    {
        "title": "ä¸­å›½ç§‘æŠ€è‚¡ç›‘ç®¡æ”¿ç­–å˜åŒ–åŠæŠ•èµ„æœºä¼š",
        "company": "è…¾è®¯æ§è‚¡", 
        "institution": "ä¸­é‡‘å…¬å¸",
        "industry": "äº’è”ç½‘",
        "author": "é™ˆæ˜",
        "type": "è¡Œä¸šç ”ç©¶",
        "content": "ä¸­å›½ç§‘æŠ€æ¿å—è¿‘æœŸå—ç›‘ç®¡æ”¿ç­–æ”¾æ¾é©±åŠ¨ä¸Šæ¶¨ï¼Œæœ¬æ–‡èšç„¦å›½å†…æ”¿ç­–å˜åŒ–å¯¹äº’è”ç½‘å…¬å¸çš„å½±å“ï¼ŒåŒ…æ‹¬æ¸¸æˆç‰ˆå·å‘æ”¾ã€å¹³å°ç»æµç›‘ç®¡ç­‰ã€‚æŠ¥å‘Šè¯¦ç»†åˆ†æäº†è…¾è®¯ã€é˜¿é‡Œå·´å·´å’Œç¾å›¢çš„ç›‘ç®¡é£é™©å˜åŒ–ï¼Œæœªè®¨è®ºç¾è”å‚¨è´§å¸æ”¿ç­–å½±å“ã€‚"
    },
    {
        "title": "åŠ æ¯å‘¨æœŸä¸­é“¶è¡Œè‚¡çš„æŠ•èµ„ä»·å€¼åˆ†æ",
        "company": "æ‹›å•†é“¶è¡Œ", 
        "institution": "ä¸­ä¿¡è¯åˆ¸",
        "industry": "é“¶è¡Œ",
        "author": "èµµé™",
        "type": "è¡Œä¸šæ·±åº¦",
        "content": "ç¾è”å‚¨åŠ æ¯æ˜¾è‘—æ”¹å–„é“¶è¡Œå‡€æ¯å·®ï¼Œæœ¬æ–‡æµ‹ç®—å›½å†…ä¸Šå¸‚é“¶è¡Œå‡€åˆ©æ¯æ”¶å…¥å°†æå‡8-12%ã€‚é‡ç‚¹åˆ†æäº†æ‹›å•†é“¶è¡Œã€å·¥å•†é“¶è¡Œå’Œä¸­å›½é“¶è¡Œçš„å—ç›Šç¨‹åº¦ã€‚ç§‘æŠ€è‚¡ä½œä¸ºå¯¹æ¯”æ¿å—ç®€è¦æåŠï¼ŒæŒ‡å‡ºå…¶èèµ„æˆæœ¬ä¸Šå‡çš„å‹åŠ›ã€‚"
    },
    {
        "title": "ç”ŸçŒªå…»æ®–è¡Œä¸šå‘¨æœŸåè½¬ä¿¡å·åˆ†æ",
        "company": "ç‰§åŸè‚¡ä»½",  
        "institution": "é•¿æ±Ÿè¯åˆ¸",
        "industry": "å†œæ—ç‰§æ¸”",
        "author": "åˆ˜æ´‹",
        "type": "è¡Œä¸šæŠ¥å‘Š",
        "content": "èƒ½ç¹æ¯çŒªå­˜æ é‡è¿ç»­ä¸‰ä¸ªæœˆä¸‹é™ï¼Œé¢„ç¤ºçŒªå‘¨æœŸå³å°†åè½¬ã€‚æˆ‘ä»¬é¢„è®¡2024å¹´ç”ŸçŒªä»·æ ¼å°†ä¸Šæ¶¨40%ï¼Œç‰§åŸè‚¡ä»½ã€æ¸©æ°è‚¡ä»½å’Œæ–°å¸Œæœ›ç­‰é¾™å¤´å…»æ®–ä¼ä¸šç›ˆåˆ©æ”¹å–„ç©ºé—´æ˜¾è‘—ã€‚æŠ¥å‘Šæœªæ¶‰åŠç§‘æŠ€è‚¡æˆ–è´§å¸æ”¿ç­–ã€‚"
    },
    {
        "title": "å…‰ä¼äº§ä¸šé“¾ä»·æ ¼èµ°åŠ¿åŠæŠ€æœ¯è¿­ä»£åˆ†æ",
        "company": "éš†åŸºç»¿èƒ½",  
        "institution": "å›½é‡‘è¯åˆ¸",
        "industry": "ç”µåŠ›è®¾å¤‡",
        "author": "æ¨å…‰",
        "type": "äº§ä¸šé“¾ç ”ç©¶",
        "content": "ç¡…æ–™ä»·æ ¼é™è‡³100å…ƒ/kgä»¥ä¸‹ï¼Œåˆºæ¿€ä¸‹æ¸¸è£…æœºéœ€æ±‚ã€‚TOPConç”µæ± é‡äº§æ•ˆç‡çªç ´25.5%ï¼Œéš†åŸºç»¿èƒ½ã€é€šå¨è‚¡ä»½å’Œæ™¶ç§‘èƒ½æºæŠ€æœ¯é¢†å…ˆã€‚æŠ¥å‘Šåˆ†æå…‰ä¼è¡Œä¸šä¾›éœ€æ ¼å±€ï¼Œä¸ç§‘æŠ€è‚¡å’Œè´§å¸æ”¿ç­–æ— ç›´æ¥å…³è”ã€‚"
    },
    {
        "title": "ç¾å€ºæ”¶ç›Šç‡ä¸Šå‡å¯¹ç§‘æŠ€è‚¡ETFçš„å½±å“",
        "company": "", 
        "institution": "åæ³°è¯åˆ¸",
        "industry": "é‡‘èäº§å“",
        "author": "å‘¨æ¶›",
        "type": "åŸºé‡‘ç ”ç©¶",
        "content": "åˆ†æ10å¹´æœŸç¾å€ºæ”¶ç›Šç‡ä¸Šå‡å¯¹ç§‘æŠ€è¡Œä¸šETF(å¦‚XLKã€QQQ)çš„å½±å“æœºåˆ¶ã€‚æŠ¥å‘ŠæŒ‡å‡ºåˆ©ç‡ä¸Šå‡1%å°†å¯¼è‡´ç§‘æŠ€ETFä¼°å€¼ä¸‹é™10-15%ï¼Œä½†æœªè®¨è®ºå…·ä½“ç§‘æŠ€å…¬å¸åŸºæœ¬é¢å˜åŒ–ã€‚é‡ç‚¹æ¯”è¾ƒäº†ä¸åŒETFäº§å“çš„ä¹…æœŸå’Œåˆ©ç‡æ•æ„Ÿæ€§ã€‚"
    }
]

# Define document type labels (used for displaying positive and negative example tags)
doc_types = {
    0: "æ­£ä¾‹",
    1: "éš¾è´Ÿä¾‹",
    2: "éš¾è´Ÿä¾‹",
    3: "éš¾è´Ÿä¾‹",
    4: "éšæœºè´Ÿä¾‹",
    5: "éšæœºè´Ÿä¾‹",
    6: "éš¾è´Ÿä¾‹"
}

# Format the documents into structured text to enhance the model's understanding
formatted_docs = []
for doc in documents:
    text = (
        f"æ–‡ç« æ ‡é¢˜ï¼š{doc['title']}\n"
        f"å…¬å¸åç§°ï¼š{doc['company']}\n"
        f"å‘å¸ƒæœºæ„ï¼š{doc['institution']}\n"
        f"è¡Œä¸šï¼š{doc['industry']}\n"
        f"ä½œè€…ï¼š{doc['author']}\n"
        f"{doc['type']}ï¼š{doc['content']}"
    )
    formatted_docs.append(text)

# Concatenate the query and all documents as a single input
all_texts = [optimized_query] + formatted_docs

# Generate sentence embeddings (the first one is the query embedding, followed by document embeddings)
embeddings = model.encode(all_texts)

# Split the query embedding and the document embeddings
query_vector = embeddings[0]
doc_vectors = embeddings[1:]

# Compute dot product similarity (can be used as an alternative to cosine similarity)
scores = query_vector @ doc_vectors.T

# Output the query content
print("ã€æŸ¥è¯¢ã€‘:", query)
print("ã€æ–‡æ¡£åŒ¹é…åˆ†æ•°ã€‘:")

# Sort all documents by score (from highest to lowest)
sorted_indices = np.argsort(scores)[::-1]

# Output each document's score, label, and key information in sequence
for idx in sorted_indices:
    doc = documents[idx]
    print(f"åˆ†æ•°: {scores[idx]:.4f} | ç±»å‹: {doc_types[idx]} | æ ‡é¢˜: {doc['title']} | æœºæ„: {doc['institution']},å†…å®¹: {doc['content'][:60]}...")

#ã€æŸ¥è¯¢ã€‘: ç¾è”å‚¨åŠ æ¯å¯¹ç§‘æŠ€è‚¡çš„å½±å“
# ã€æ–‡æ¡£åŒ¹é…åˆ†æ•°ã€‘:
# åˆ†æ•°: 0.9015 | ç±»å‹: æ­£ä¾‹ | æ ‡é¢˜: ç¾è”å‚¨åŠ æ¯å¯¹ç§‘æŠ€è‚¡ä¼°å€¼å½±å“åˆ†æ | æœºæ„: æ‘©æ ¹å£«ä¸¹åˆ© | å†…å®¹: 2023å¹´ç¾è”å‚¨è¿ç»­åŠ æ¯å¯¼è‡´ç§‘æŠ€è‚¡ä¼°å€¼å¤§å¹…å›è°ƒï¼Œç‰¹åˆ«æ˜¯é«˜æˆé•¿...
# åˆ†æ•°: 0.8482 | ç±»å‹: éš¾è´Ÿä¾‹ | æ ‡é¢˜: ç¾è”å‚¨åŠ æ¯å¯¹å…¨çƒèµ„äº§é…ç½®çš„å½±å“ | æœºæ„: ç‘é“¶ | å†…å®¹: æœ¬æ–‡ç³»ç»Ÿåˆ†æç¾è”å‚¨åŠ æ¯å¯¹å…¨çƒè‚¡å€ºæ±‡å¸‚çš„å½±å“ï¼Œç§‘æŠ€è‚¡ä½œä¸ºæƒç›Šèµ„...
# åˆ†æ•°: 0.8167 | ç±»å‹: éš¾è´Ÿä¾‹ | æ ‡é¢˜: ç¾å€ºæ”¶ç›Šç‡ä¸Šå‡å¯¹ç§‘æŠ€è‚¡ETFçš„å½±å“ | æœºæ„: åæ³°è¯åˆ¸ | å†…å®¹: åˆ†æ10å¹´æœŸç¾å€ºæ”¶ç›Šç‡ä¸Šå‡å¯¹ç§‘æŠ€è¡Œä¸šETF(å¦‚XLKã€QQQ...
# åˆ†æ•°: 0.7839 | ç±»å‹: éš¾è´Ÿä¾‹ | æ ‡é¢˜: åŠ æ¯å‘¨æœŸä¸­é“¶è¡Œè‚¡çš„æŠ•èµ„ä»·å€¼åˆ†æ | æœºæ„: ä¸­ä¿¡è¯åˆ¸ | å†…å®¹: ç¾è”å‚¨åŠ æ¯æ˜¾è‘—æ”¹å–„é“¶è¡Œå‡€æ¯å·®ï¼Œæœ¬æ–‡æµ‹ç®—å›½å†…ä¸Šå¸‚é“¶è¡Œå‡€åˆ©æ¯æ”¶å…¥...
# åˆ†æ•°: 0.7562 | ç±»å‹: éš¾è´Ÿä¾‹ | æ ‡é¢˜: ä¸­å›½ç§‘æŠ€è‚¡ç›‘ç®¡æ”¿ç­–å˜åŒ–åŠæŠ•èµ„æœºä¼š | æœºæ„: ä¸­é‡‘å…¬å¸ | å†…å®¹: ä¸­å›½ç§‘æŠ€æ¿å—è¿‘æœŸå—ç›‘ç®¡æ”¿ç­–æ”¾æ¾é©±åŠ¨ä¸Šæ¶¨ï¼Œæœ¬æ–‡èšç„¦å›½å†…æ”¿ç­–å˜åŒ–...
# åˆ†æ•°: 0.6164 | ç±»å‹: éšæœºè´Ÿä¾‹ | æ ‡é¢˜: å…‰ä¼äº§ä¸šé“¾ä»·æ ¼èµ°åŠ¿åŠæŠ€æœ¯è¿­ä»£åˆ†æ | æœºæ„: å›½é‡‘è¯åˆ¸ | å†…å®¹: ç¡…æ–™ä»·æ ¼é™è‡³100å…ƒ/kgä»¥ä¸‹ï¼Œåˆºæ¿€ä¸‹æ¸¸è£…æœºéœ€æ±‚ã€‚TOPCo...
# åˆ†æ•°: 0.6151 | ç±»å‹: éšæœºè´Ÿä¾‹ | æ ‡é¢˜: ç”ŸçŒªå…»æ®–è¡Œä¸šå‘¨æœŸåè½¬ä¿¡å·åˆ†æ | æœºæ„: é•¿æ±Ÿè¯åˆ¸ | å†…å®¹: èƒ½ç¹æ¯çŒªå­˜æ é‡è¿ç»­ä¸‰ä¸ªæœˆä¸‹é™ï¼Œé¢„ç¤ºçŒªå‘¨æœŸå³å°†åè½¬ã€‚æˆ‘ä»¬é¢„è®¡2...
```



## FIR-bench Evaluation Benchmark for Fin-Retrievers

| Dataset | Description |
|--|--|
| [FIR-Bench-Sin-Doc-FinQA](https://huggingface.co/datasets/valuesimplex-ai-lab/FIR-Bench-Sin-Doc-FinQA) | Single-document Q&A dataset |
| [FIR-Bench-Multi-Docs-FinQA](https://huggingface.co/datasets/valuesimplex-ai-lab/FIR-Bench-Multi-Docs-FinQA) | Multi-document Q&A dataset |
| [FIR-Bench-Research-Reports-FinQA](https://huggingface.co/datasets/valuesimplex-ai-lab/FIR-Bench-Research-Reports-FinQA) | Research report Q&A dataset |
| [FIR-Bench-Announcements-FinQA](https://huggingface.co/datasets/valuesimplex-ai-lab/FIR-Bench-Announcements-FinQA) | Announcement Q&A dataset |
| [FIR-Bench-Indicators-FinQA] | Indicator Q&A dataset (In Preparation) |

## Model List

| Model | Description |
|--|--|
| [**FinBERT2-base (Pre-trained Model)**](https://huggingface.co/valuesimplex-ai-lab/FinBERT2-base) | BERT-base language model pre-trained on 32 billion Chinese financial texts with additional financial domain tokenization |
| [**FinBERT2-large (Pre-trained Model)**](https://huggingface.co/valuesimplex-ai-lab/FinBERT2-large) | BERT-large language model pre-trained on 32 billion Chinese financial texts with additional financial domain tokenization |
| [**Fin-Retrievers-base (Retrieval Task Fine-tuned Model)**](https://huggingface.co/valuesimplex-ai-lab/Fin-Retriever-base) | Financial domain enhanced retrieval model |


## Updates
- February/2025: Created FinBERT2 GitHub project
- May/2025: FinBERT2 paper accepted by KDD 2025 ADS (Applied Data Science) track
- June/2025: Updated FinBERT2 GitHub project

## Reference:
Our suite is developed based on the following open-source projects. For more details, please refer to the original repositories:

- [**FinBERT1**](https://github.com/valuesimplex/FinBERT): The first-generation FinBERT by EntropyReduce Technology
- [**RoBERTa Chinese Pre-trained Model**](https://github.com/ymcui/Chinese-BERT-wwm): A Chinese language model pre-trained on large-scale Chinese corpus using RoBERTa method
- [**SentencePiece (Tokenization Tool)**](https://github.com/google/sentencepiece): An unsupervised text tokenizer developed by Google for neural network-based text generation tasks
- [**BGE Embedding (General Embedding Model)**](https://github.com/FlagOpen/FlagEmbedding): An open-source project aimed at developing retrieval and retrieval-augmented language models
- [**BERTopic**](https://github.com/MaartenGr/BERTopic): An advanced topic model that leverages BERT and class-based TF-IDF to create interpretable topics



## Citation

If you find our work helpful, please consider giving us a star :star: and citing the following paper:
```
@inproceedings{xu2025finbert2,
  author = {Xu Xuan and Wen Fufang and Chu Beilin and Fu Zhibing and Lin Qinhong and Liu Jiaqi and Fei Binjie and Li Yu and Zhou Linna and Yang Zhongliang},
  title = {FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in Finance-Specific Deployment of Large Language Models},
  booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2 (KDD '25)},
  year = {2025},
  doi = {10.1145/3711896.3737219},
  url = {https://doi.org/10.1145/3711896.3737219}
}
```
## License
Licensed under the [MIT License](LICENSE).
